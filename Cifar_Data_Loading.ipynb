{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar Data Loading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kax84F_fn3rN",
        "outputId": "827e0fec-c015-4280-a5b8-13a2ab64ad81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "!wget wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-06 15:55:28--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2020-10-06 15:55:28--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  74.5MB/s    in 2.2s    \n",
            "\n",
            "2020-10-06 15:55:30 (74.5 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "FINISHED --2020-10-06 15:55:30--\n",
            "Total wall clock time: 2.5s\n",
            "Downloaded: 1 files, 163M in 2.2s (74.5 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGNZNvpon6ql",
        "outputId": "5c6a0fe3-4556-4cc1-bc64-c0b61c758c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!tar -xzvf /content/cifar-10-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uJMbkRCoxxp"
      },
      "source": [
        "import cv2\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twO-wjGuoCpT",
        "outputId": "56726a2c-f965-4636-8b8d-895e6ff5da6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# Preparing datasets for further using\n",
        "# Loading all batches and concatenating them all together\n",
        "# Plotting first 100 examples of images from 10 different classes\n",
        "# Preprocessing loaded CIFAR-10 dataset\n",
        "# Saving datasets into file\n",
        "\n",
        "\n",
        "\"\"\"Importing library for object serialization\n",
        "which we'll use for saving and loading serialized models\"\"\"\n",
        "import pickle\n",
        "\n",
        "# Importing other standard libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Defining function for loading single batch of CIFAR-10 dataset\n",
        "def single_batch_cifar10(file):\n",
        "    # Opening file for reading in binary mode\n",
        "    with open(file, 'rb') as f_single_batch:\n",
        "        d_single_batch = pickle.load(f_single_batch, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n",
        "        x = d_single_batch['data']  # numpy.ndarray type, (10000, 3072)\n",
        "        y = d_single_batch['labels']  # list type\n",
        "        \"\"\"Initially every batch's dictionary with key 'data' has shape (10000, 3072)\n",
        "        Where, 10000 - number of image samples\n",
        "        3072 - three channels of image (red + green + blue)\n",
        "        Every row contains an image 32x32 pixels with its three channels\"\"\"\n",
        "        # Here we reshape and transpose ndarray for further use\n",
        "        # At the same time method 'astype()' used for converting ndarray from int to float\n",
        "        # It is used further in function 'pre_process_cifar10' as it is needed to subtract float from float\n",
        "        # And for standard deviation as it is needed to divide float by float\n",
        "        x = x.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype('float')  # (10000, 32, 32, 3)\n",
        "        # Making numpy array from list of labels\n",
        "        y = np.array(y)\n",
        "\n",
        "        # Returning ready data\n",
        "        return x, y\n",
        "\n",
        "\n",
        "# Defining function for loading whole CIFAR-10 dataset\n",
        "def whole_cifar10():\n",
        "    # Defining lists for adding all batch's data all together\n",
        "    x_collect = []\n",
        "    y_collect = []\n",
        "\n",
        "    # Defining lists for loading current batch\n",
        "    x, y = [], []\n",
        "\n",
        "    # Loading all 5 batches for training and appending them together\n",
        "    for k in range(1, 6):\n",
        "        # Preparing current filename\n",
        "        filename = os.path.join('/content/cifar-10-batches-py', 'data_batch_' + str(k))\n",
        "        # Loading current batch\n",
        "        x, y = single_batch_cifar10(filename)\n",
        "        # Appending data from current batch to lists\n",
        "        x_collect.append(x)\n",
        "        y_collect.append(y)\n",
        "\n",
        "    # Concatenating collected data as list of lists as one list\n",
        "    x_train = np.concatenate(x_collect)  # (50000, 32, 32, 3)\n",
        "    y_train = np.concatenate(y_collect)  # (50000,)\n",
        "\n",
        "    # Releasing memory from non-needed anymore arrays\n",
        "    del x, y\n",
        "\n",
        "    # Loading data for testing\n",
        "    filename = os.path.join('/content/cifar-10-batches-py', 'test_batch')\n",
        "    x_test, y_test = single_batch_cifar10(filename)\n",
        "    \n",
        "    # Returning whole CIFAR-10 data for training and testing\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\t\n",
        "# Defining function for preprocessing CIFAR-10 dataset\n",
        "def pre_process_cifar10():\n",
        "    # Loading whole CIFAR-10 dataset\n",
        "    x_train, y_train, x_test, y_test = whole_cifar10()\n",
        "\n",
        "    # Normalizing whole data by dividing /255.0\n",
        "    x_train /= 255.0\n",
        "    x_test /= 255.0\n",
        "\n",
        "    # Preparing data for training, validation and testing\n",
        "    # Data for validation is taken with 1000 examples from training dataset in range from 49000 to 50000\n",
        "    batch_mask = list(range(49000, 50000))\n",
        "    x_validation = x_train[batch_mask]  # (1000, 32, 32, 3)\n",
        "    y_validation = y_train[batch_mask]  # (1000,)\n",
        "    # Data for training is taken with first 49000 examples from training dataset\n",
        "    batch_mask = list(range(49000))\n",
        "    x_train = x_train[batch_mask]  # (49000, 32, 32, 3)\n",
        "    y_train = y_train[batch_mask]  # (49000,)\n",
        "    # Data for testing is taken with first 1000 examples from testing dataset\n",
        "    batch_mask = list(range(1000))\n",
        "    x_test = x_test[batch_mask]  # (1000, 32, 32, 3)\n",
        "    y_test = y_test[batch_mask]  # (1000,)\n",
        "\n",
        "    # Normalizing data by subtracting mean image and dividing by standard deviation\n",
        "    # Subtracting the dataset by mean image serves to center the data\n",
        "    # It helps for each feature to have a similar range and gradients don't go out of control\n",
        "    # Calculating mean image from training dataset along the rows by specifying 'axis=0'\n",
        "    mean_image = np.mean(x_train, axis=0)  # numpy.ndarray (32, 32, 3)\n",
        "\n",
        "    # Calculating standard deviation from training dataset along the rows by specifying 'axis=0'\n",
        "    std = np.std(x_train, axis=0)  # numpy.ndarray (32, 32, 3)\n",
        "    # Saving calculated 'mean_image' and 'std' into 'pickle' file\n",
        "    # We will use them when preprocess input data for classifying\n",
        "    # We will need to subtract and divide input image for classifying\n",
        "    # As we're doing now for training, validation and testing data\n",
        "    dictionary = {'mean_image': mean_image, 'std': std}\n",
        "    with open('mean_and_std.pickle', 'wb') as f_mean_std:\n",
        "        pickle.dump(dictionary, f_mean_std)\n",
        "\n",
        "    # Subtracting calculated mean image from datasets\n",
        "    x_train -= mean_image\n",
        "    x_validation -= mean_image\n",
        "    x_test -= mean_image\n",
        "\n",
        "    # Dividing then every dataset by standard deviation\n",
        "    x_train /= std\n",
        "    x_validation /= std\n",
        "    x_test /= std\n",
        "\n",
        "    # Transposing every dataset to make channels come first\n",
        "    x_train = x_train.transpose(0, 3, 1, 2)  # (49000, 3, 32, 32)\n",
        "    x_test = x_test.transpose(0, 3, 1, 2)  # (1000, 3, 32, 32)\n",
        "    x_validation = x_validation.transpose(0, 3, 1, 2)  # (1000, 3, 32, 32)\n",
        "\n",
        "    # Returning result as dictionary\n",
        "    d_processed = {'x_train': x_train, 'y_train': y_train,\n",
        "                   'x_validation': x_validation, 'y_validation': y_validation,\n",
        "                   'x_test': x_test, 'y_test': y_test}\n",
        "\n",
        "    # Returning dictionary\n",
        "    return d_processed\n",
        "\n",
        "\n",
        "# Preprocessing data\n",
        "data = pre_process_cifar10()\n",
        "for i, j in data.items():\n",
        "    print(i + ':', j.shape)\n",
        "\n",
        "# x_train: (49000, 3, 32, 32)\n",
        "# y_train: (49000,)\n",
        "# x_validation: (1000, 3, 32, 32)\n",
        "# y_validation: (1000,)\n",
        "# x_test: (1000, 3, 32, 32)\n",
        "# y_test: (1000,)\n",
        "\n",
        "# Saving loaded and preprocessed data into 'pickle' file\n",
        "with open('data.pickle', 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train: (49000, 3, 32, 32)\n",
            "y_train: (49000,)\n",
            "x_validation: (1000, 3, 32, 32)\n",
            "y_validation: (1000,)\n",
            "x_test: (1000, 3, 32, 32)\n",
            "y_test: (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wfdsBavoY4T"
      },
      "source": [
        "x_train,y_train,x_test,y_test = whole_cifar10()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoxYze85Hp5H",
        "outputId": "d57e83f6-e141-48d6-984f-67a1d06f6ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_train[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxrGCcoJo-rz",
        "outputId": "4386c4f7-39b1-4c72-d067-b2bc945558d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N06fwApPCiCA",
        "outputId": "2d0e22af-3b2d-4312-fc12-741abde47554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "im1 = x_train[1]\n",
        "im1.shape\n",
        "plt.imshow(im1)\n",
        "cv2.imwrite(\"im.jpg\",im1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhmMHF_MEbL_",
        "outputId": "d21cb5dc-8e9c-4598-90e6-cf1f84e30bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "im1[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[154., 177., 187.],\n",
              "       [126., 137., 136.],\n",
              "       [105., 104.,  95.],\n",
              "       [102., 101.,  99.],\n",
              "       [125., 131., 139.],\n",
              "       [155., 166., 180.],\n",
              "       [172., 190., 210.],\n",
              "       [180., 199., 214.],\n",
              "       [142., 156., 156.],\n",
              "       [111., 120., 110.],\n",
              "       [106., 107.,  98.],\n",
              "       [109., 104., 102.],\n",
              "       [123., 121., 117.],\n",
              "       [127., 129., 127.],\n",
              "       [181., 188., 189.],\n",
              "       [217., 226., 229.],\n",
              "       [209., 211., 211.],\n",
              "       [166., 167., 162.],\n",
              "       [164., 165., 156.],\n",
              "       [158., 160., 148.],\n",
              "       [116., 117., 103.],\n",
              "       [102., 101.,  83.],\n",
              "       [ 95.,  95.,  76.],\n",
              "       [ 90.,  89.,  79.],\n",
              "       [ 72.,  70.,  69.],\n",
              "       [ 60.,  60.,  61.],\n",
              "       [ 56.,  57.,  54.],\n",
              "       [ 77.,  78.,  72.],\n",
              "       [ 94.,  96.,  84.],\n",
              "       [ 91.,  95.,  71.],\n",
              "       [ 87.,  90.,  71.],\n",
              "       [ 79.,  81.,  70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NANsPXiho8aC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}